#!/bin/bash

# site-level pipeline script for final accounting of per subject pipeline outputs from audio and transcript sides
# should be called with path to config file for that site's settings as main argument
if [[ -z "${1}" ]]; then
	echo "Please provide a path to settings file"
	exit
fi
config_path=$1

# start by getting the absolute path to the directory this script is in, which will be within folder site_level_pipeline_branches of the repo
# this way script will work even if the repo is downloaded to a new location, rather than relying on hard coded paths to where I put it 
full_path=$(realpath $0)
pipelines_root=$(dirname $full_path)
# all of the helpers to be called here can be found in a subfolder of the site-level wrappers folder
func_root="$pipelines_root"/subject_level_functions
# also get root of repository for logging output purposes
repo_root="$pipelines_root"/..

# running config file will set up necessary environment variables
source "$config_path"

# make directory for logs if needed
if [[ ! -d ${repo_root}/logs ]]; then
	mkdir "$repo_root"/logs
fi
# keep logs in individual directories per site
if [[ ! -d ${repo_root}/logs/${site} ]]; then
	mkdir "$repo_root"/logs/"$site"
fi
# save with unique timestamp (unix seconds)
log_timestamp=`date +%s`
# if running manually, print to console and log files simultaneously
exec >  >(tee -ia "$repo_root"/logs/"$site"/summary_process_logging_"$log_timestamp".txt)
exec 2> >(tee -ia "$repo_root"/logs/"$site"/summary_process_logging_"$log_timestamp".txt >&2)

cur_date=$(date +%Y%m%d) # formatted date for possible CSV logging

# confirm highest level folder structure exists as it should for given site
# (note it may not because of an issue or just because a planned site hasn't actually started enrolling yet - or if writing your own config, a settings issue)
cd "$data_root"/PROTECTED
if [[ ! -d $site ]]; then
	echo "ERROR: invalid data root path ${data_root} or site ID ${site}, as necessary base folder structure does not exist"
	exit
fi
if [[ ! -d ../GENERAL/$site ]]; then
	echo "ERROR: invalid data root path ${data_root} or site ID ${site}, as necessary base folder structure does not exist"
	exit
fi
if [[ ! -d $site/raw ]]; then
	echo "ERROR: site folder ${site} improperly or not yet completely setup"
	exit
fi
if [[ ! -d $site/processed ]]; then
	echo "ERROR: site folder ${site} improperly or not yet completely setup"
	exit
fi
# don't care if there is a raw in GENERAL as I will never use that part, so excluding that check - but do need processed!
if [[ ! -d ../GENERAL/$site/processed ]]; then
	echo "ERROR: site folder ${site} improperly or not yet completely setup"
	exit
fi
if [[ ! -e ../GENERAL/${site}/${site}_metadata.csv ]]; then
	echo "ERROR: site ${site} missing necessary subject enrollment metadata"
	exit
fi

# let user know script is starting and give basic settings info for reference
echo ""
echo "Beginning site-level daily journal summary processing pipeline run for:"
echo "$site"
echo "with data root:"
echo "$data_root"

# add current time for runtime tracking purposes
now=$(date +"%T")
echo "Current time: ${now}"
echo ""
                                               
cd "$data_root"/PROTECTED/"$site"/processed
echo "Looping through available subject IDs"
echo ""
for p in *; do
	# only bother with participants that have ever had some pipeline outputs generated by either side before   
	if [[ ! -d $p/phone/audio_journals/file_accounting_details ]]; then
		echo "${p} has no record of diary pipeline outputs, continuing to next subject"
		echo ""
		continue
	fi
	if [[ ! -e $p/phone/audio_journals/file_accounting_details/${site}_${p}_audioJournalJSONRecordsInfo.csv ]]; then
		if [[ ! -e $p/phone/audio_journals/file_accounting_details/${site}_${p}_availablePhoneMP3sAccounting.csv ]]; then
			echo "${p} has only EMA-related diary pipeline outputs, continuing to next subject"
			echo ""
			continue
		fi
	fi
	cd "$p"/phone/audio_journals

	echo "Checking for major red flags in file structure of PROTECTED processed for ${p} audio journals"
	echo "(if anything detected it will be logged here in addition to creating record in CSV)"
	now=$(date +"%T")
	echo "Current time: ${now}"

	# first checking through folders that should not exist when everything is going smoothly
	if [[ -d crashed_audio ]]; then
		if [ -z "$(ls -A crashed_audio)" ]; then
			# just missing cleanup, can ignore
			rm -rf crashed_audio
			# though this indicates some sort of manual intervention, as pipeline should never have this happen
			# so log some code warning in case
			echo "WARNING: crashed_audio folder found for subject ${p}, but it was empty - if this is unexpected perhaps look into it further"
		else
			# actual problem! 
			echo "Audios that failed to complete audio QC detected! Please see phone crashed_audio folder for subject ${p}"
			echo "(these may or may not be brand new, but it indicates there are likely still unresolved issues at this time - or incomplete clean up after fixing an issue)"
			# create the issues log if needed
			if [[ ! -e ${site}_${p}_audioJournalMajorIssuesLog.csv ]]; then
				echo "date_detected,site,subject,filename,file_stage,error_message" > "$site"_"$p"_audioJournalMajorIssuesLog.csv
			fi
			cd crashed_audio
			for file in *.wav; do
				echo "${cur_date},${site},${p},${file},pre-audioQC,Audio QC function crashed" >> ../"$site"_"$p"_audioJournalMajorIssuesLog.csv
			done
			cd ..
		fi
	fi
	if [[ -d audio_to_send ]]; then
		if [ -z "$(ls -A audio_to_send)" ]; then
			# just missing cleanup, can ignore
			rm -rf audio_to_send
		else
			# actual problem! 
			echo "Audios that failed to upload to TranscribeMe detected! Please see phone type audio_to_send folder for subject ${p}"
			echo "(these may or may not be brand new, but it indicates there are still upload failures at this time)"
			# create the issues log if needed
			if [[ ! -e ${site}_${p}_audioJournalMajorIssuesLog.csv ]]; then
				echo "date_detected,site,subject,filename,file_stage,error_message" > "$site"_"$p"_audioJournalMajorIssuesLog.csv
			fi
			cd audio_to_send
			for file in *.wav; do
				echo "${cur_date},${site},${p},${file},pre-transcript,TranscribeMe SFTP upload failed" >> ../"$site"_"$p"_audioJournalMajorIssuesLog.csv
			done
			cd ..
		fi
	fi
	if [[ -d temp_audio ]]; then
		if [ -z "$(ls -A temp_audio)" ]; then
			# just missing cleanup, can ignore
			rm -rf temp_audio
			# though this shouldn't really happen within scope of pipeline
			# - might be somthing weird, so log some code warning in case
			echo "WARNING: temp_audio folder found for subject ${p}, but it was empty - may or may not be a concern"
		else
			# actual problem! 
			echo "Audios left in temp_audio detected! This should not happen in normal operation of pipeline (with all error catching), so unclear what it means. Please see processed audio journal outputs for subject ${p}"
			echo "(these may or may not be brand new, but it indicates there is still something odd happening at this time)"
			# create the issues log if needed
			if [[ ! -e ${site}_${p}_audioJournalMajorIssuesLog.csv ]]; then
				echo "date_detected,site,subject,filename,file_stage,error_message" > "$site"_"$p"_audioJournalMajorIssuesLog.csv
			fi
			cd temp_audio
			for file in *.wav; do
				echo "${cur_date},${site},${p},${file},pre-audioQC,File left in temp_audio folder (error cause unknown)" >> ../"$site"_"$p"_audioJournalMajorIssuesLog.csv
			done
			cd ..
		fi
	fi
	# raw file tracking system folder will obviously exist if processing has happened for a diary
	# - but shouldn't have anything left with TODO, and existence should check out
	if [[ -d raw_file_tracking_system ]]; then
		cd raw_file_tracking_system
		for file in TODO*.txt; do
			if [[ -z $file ]]; then
				# ideally there will be none and will just skip over
				continue
			fi
			# create issues log if needed
			if [[ ! -e ../${site}_${p}_audioJournalMajorIssuesLog.csv ]]; then
				echo "date_detected,site,subject,filename,file_stage,error_message" > ../"$site"_"$p"_audioJournalMajorIssuesLog.csv
			fi
			echo "${file} failed ffmpeg conversion"
			echo "${cur_date},${site},${p},${file},pre-wav,Audio conversion to WAV failed" >> ../"$site"_"$p"_audioJournalMajorIssuesLog.csv
		done
		# now check normal completed ones to make sure downstream stuff exists as expected
		for file in U*.txt; do
			if [[ -z $file ]]; then
				# in case no processing at all, though generally shouldn't hit this here
				continue
			fi
			# get what name of completed WAV would be
			output_name=$(cat ${file})
			if [[ ! -e ../completed_audio/${output_name} ]]; then
				if [[ ! -e ../rejected_audio/${output_name} ]]; then
					if [[ ! -e ../pending_audio/${output_name} ]]; then
						# if not in normal locations also check the error locations already logged so don't duplicate
						if [[ ! -e ../crashed_audio/${output_name} ]]; then
							if [[ ! -e ../audio_to_send/${output_name} ]]; then
								if [[ ! -e ../temp_audio/${output_name} ]]; then
									# real issue finding the audio! 
									# may be normal if choose to clear out converted diaries for space, but not default
									echo "Failed to find corresponding audio under subject ${p} processed for raw diary record ${file}"
									# create issues log if needed
									if [[ ! -e ../${site}_${p}_audioJournalMajorIssuesLog.csv ]]; then
										echo "date_detected,site,subject,filename,file_stage,error_message" > ../"$site"_"$p"_audioJournalMajorIssuesLog.csv
									fi
									echo "${cur_date},${site},${p},${file},pre-wav,Audio conversion to WAV marked as complete but subsequently missing (if not intentionally deleted definitely a problem)" >> ../"$site"_"$p"_audioJournalMajorIssuesLog.csv
								fi
							fi
						fi
					fi
				fi
			fi
		done
		cd ..
	fi

	# also have a few things to double check with the transcripts if any exist yet
	if [[ -d transcripts ]]; then
		cd transcripts
		for file in *.txt; do
			if [[ -z $file ]]; then
				# make sure there actually are transcript txts
				continue
			fi
			txt_root=$(echo "$file" | awk -F '.txt' '{print $1}') 
			# if final end point doesnt exist for pulled transcript something went wrong
			if [[ ! -e redacted_csvs_with_stats/${txt_root}_REDACTED_withSentenceStats.csv ]]; then
				# create the issues log if needed
				if [[ ! -e ../${site}_${p}_audioJournalMajorIssuesLog.csv ]]; then
					echo "date_detected,site,subject,filename,file_stage,error_message" > ../"$site"_"$p"_audioJournalMajorIssuesLog.csv
				fi
				# find stage it is first missing at
				if [[ ! -e redacted_copies/csv/${txt_root}_REDACTED.csv ]]; then
					if [[ ! -e redacted_copies/${txt_root}_REDACTED.txt ]]; then
						echo "${file} failed transcript redaction step - may be an encoding issue?"
						echo "${cur_date},${site},${p},${file},pre-transcriptQC,Automatic redaction of marked PII in returned transcript failed" >> ../"$site"_"$p"_audioJournalMajorIssuesLog.csv
					else
						echo "${file} failed transcript CSV conversion"
						echo "${cur_date},${site},${p},${file},pre-transcriptQC,Conversion of transcript text file to CSV failed" >> ../"$site"_"$p"_audioJournalMajorIssuesLog.csv
					fi
				else
					echo "${file} failed final transcript processing step"
					echo "${cur_date},${site},${p},${file},post-transcriptQC,Calculation of transcript stats per sentence failed" >> ../"$site"_"$p"_audioJournalMajorIssuesLog.csv
				fi
			fi
		done
		cd ..
	fi
	# and similarly make sure anything marked as completed checks out as having a transcript
	if [[ -d completed_audio ]]; then
		cd completed_audio
		for file in *.wav; do
			if [[ -z $file ]]; then
				# make sure there actually are wavs
				continue
			fi
			wav_root=$(echo "$file" | awk -F '.wav' '{print $1}') 
			if [[ ! -e ../transcripts/${wav_root}.txt ]]; then
				# create issues log if needed
				if [[ ! -e ../${site}_${p}_audioJournalMajorIssuesLog.csv ]]; then
					echo "date_detected,site,subject,filename,file_stage,error_message" > ../"$site"_"$p"_audioJournalMajorIssuesLog.csv
				fi
				echo "${file} is marked as completed audio but matching transcript pull not found"
				echo "${cur_date},${site},${p},${file},pre-transcript,Audio marked as completed but pulled transcript not found" >> ../"$site"_"$p"_audioJournalMajorIssuesLog.csv
			fi
		done
		cd ..
	fi

	echo "Now reviewing QC/accounting CSVs for subject ${p} audio journals to finalize major issues log"
	echo "(if anything detected it will be logged here in addition to creating record in CSV)"
	now=$(date +"%T")
	echo "Current time: ${now}"

	# python function for finishing audioJournalMajorIssuesLog.csv updates for this subject
	python "$func_root"/journal_outputs_error_check.py "$data_root" "$site" "$p"
	# checks audio QC exists for anything in completed_audio and pending_audio
	# checks transcript QC exists for anything in transcripts/redacted_copies/csv
	# checks if something has been in pending_audio for more than 2 weeks
	# logs any json records with missing diary MP3 paths and any MP3s with missing json record
	# finally cleans up issues log to remove duplicates (keeping oldest date) at end

	echo "Finally, creating merged QC and accounting info CSV for successful subject ${p} audio journals, and splitting out info on WAVs rejected by QC"
	now=$(date +"%T")
	echo "Current time: ${now}"

	# python function separates out rejected audio QC table
	# also separates out successful audio table and have it merged with stats from various other tables
	python "$func_root"/diary_qc_compilation.py "$data_root" "$site" "$p"

	echo "${p} has completed new diary summary processing!"
	now=$(date +"%T")
	echo "Current time: ${now}"
	echo ""
	cd "$data_root"/PROTECTED/"$site"/processed # at end of loop go back to start spot
done

echo "Subject summaries journals script completed for all current subjects of site ${site}!"
# note doing email alerts for this pipeline only at the server-wide level
